{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, re, json, traceback, sys, copy, urllib\n",
    "import urllib.request as urlopen\n",
    "import urllib.request as request\n",
    "import requests\n",
    "\n",
    "from arcgis.gis import GIS\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# used to prompt for user input\n",
    "# when using this script internally, you may remove this and simply hard code in your username and password\n",
    "import getpass\n",
    "\n",
    "# this helps us do some debugging within the Python Notebook\n",
    "# another optional component\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a connection to your ArcGIS Online Organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in as: apfister_sdg\n"
     ]
    }
   ],
   "source": [
    "online_username = input('Username: ')\n",
    "online_password = getpass.getpass('Password: ')\n",
    "\n",
    "online_connection = \"https://www.arcgis.com\"\n",
    "gis_online_connection = GIS(online_connection, online_username, online_password)\n",
    "\n",
    "user = gis_online_connection.properties.user.username\n",
    "print ('Logged in as: ' + user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the CSV file \n",
    "Using the ArcGIS REST API `analyze` endpoint, we can prepare the CSV file we are going to use before publishing it to ArcGIS Online. This will help us by returning information about the file inlcuding fields as well as sample records. This step will also lead into future steps in the publishing process.\n",
    "\n",
    "More info about the analyze endpoint can be found [here](https://developers.arcgis.com/rest/users-groups-and-items/analyze.htm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analyze_csv(item_id):\n",
    "    try:\n",
    "        sharing_url = gis_online_connection.content._gis._url + \"/sharing/rest/content/features/analyze\"\n",
    "        analyze_params = {'f': 'json', 'token': gis_online_connection._con._token,\n",
    "                          'sourceLocale': 'en-us',\n",
    "                          'filetype': 'csv', 'itemid': item_id}\n",
    "        r = requests.post(sharing_url, data=analyze_params)\n",
    "        json_data = json.loads(r.content.decode(\"UTF-8\"))\n",
    "        for field in json_data[\"publishParameters\"][\"layerInfo\"][\"fields\"]:\n",
    "            field[\"alias\"] = set_field_alias(field[\"name\"])\n",
    "\n",
    "            # Indicator is coming in as a date Field make the correct\n",
    "            if field[\"name\"] == \"indicator\":\n",
    "                field[\"type\"] = \"esriFieldTypeString\"\n",
    "                field[\"sqlType\"] = \"sqlTypeNVarchar\"\n",
    "        json_data[\"publishParameters\"][\"layerInfo\"][\"displayField\"] = \"geoAreaName_x\"\n",
    "        return json_data[\"publishParameters\"]\n",
    "    except:\n",
    "        print(\"Unexpected error:\", sys.exc_info()[0])\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publish the CSV file\n",
    "This function is where the majority of the work will happen. Here is a basic outline of the steps we will take:\n",
    "- Begin by asking for the path to the CSV file itself\n",
    "- Check if the CSV file exists\n",
    "- If exists, update and move to Open Data Group\n",
    "- If it doesn't exist, publish as a new Item then move to the Open Data Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def publish_csv(series_code, item_properties, thumbnail,property_update_only=False):\n",
    "    # Do we need to publish the hosted feature service for this layer\n",
    "    try:\n",
    "        data_dir = r\"/Users/trav5516/Box Sync/Projects/UNSD - HUB Pilot/Technical/Data/Dataset-nofolders\"\n",
    "        file = os.path.join(data_dir, series_code + \".csv\")\n",
    "        if os.path.isfile(file):\n",
    "            csv_item_properties = copy.deepcopy(item_properties)\n",
    "            csv_item_properties[\"title\"] = series_code + \"_MST\"\n",
    "            csv_item_properties[\"type\"] = \"CSV\"\n",
    "            csv_item_properties[\"url\"] = \"\"\n",
    "\n",
    "            # Does this CSV already exist\n",
    "            query_string = \"title:'{}' AND owner:{}\".format(csv_item_properties[\"title\"], online_username)\n",
    "            search_results = gis_online_connection.content.search(query_string)\n",
    "\n",
    "            csv_item = None\n",
    "            print('Publishing CSV File....')\n",
    "            if search_results:\n",
    "                for search_result in search_results:\n",
    "                    if search_result[\"title\"] == csv_item_properties[\"title\"]:\n",
    "                        if property_update_only:\n",
    "                            search_result.update(item_properties=csv_item_properties, thumbnail=thumbnail)\n",
    "                        else:\n",
    "                            search_result.update(item_properties=csv_item_properties, thumbnail=thumbnail,\n",
    "                                                 data=file)\n",
    "                        csv_item = search_result\n",
    "                        break\n",
    "\n",
    "            if csv_item is None:\n",
    "                csv_item = gis_online_connection.content.add(item_properties=csv_item_properties, thumbnail=thumbnail,\n",
    "                                                             data=file)\n",
    "\n",
    "            # find the published service\n",
    "            query_string = \"title:'{}' AND owner:{}\".format(item_properties[\"title\"], online_username)\n",
    "            search_results = gis_online_connection.content.search(query_string)\n",
    "\n",
    "            if search_results:\n",
    "                for search_result in search_results:\n",
    "                    if search_result[\"title\"] == item_properties[\"title\"]:\n",
    "                        search_result.update(item_properties=item_properties, thumbnail=thumbnail)\n",
    "                        search_result.move(\"Open Data\")\n",
    "                        return search_result\n",
    "\n",
    "            # publish the layer if it was not found\n",
    "            print('Analyze Feature Service....')\n",
    "            publish_parameters = analyze_csv(csv_item[\"id\"])\n",
    "            publish_parameters[\"name\"] = csv_item_properties[\"title\"]\n",
    "            print('Publishing Feature Service....')\n",
    "            csv_lyr = csv_item.publish(publish_parameters=publish_parameters,overwrite=True)\n",
    "            csv_lyr.update(item_properties=item_properties, thumbnail=thumbnail)\n",
    "            if csv_item[\"ownerFolder\"] is None:\n",
    "                print('Moving CSV to Open Data Folder')\n",
    "                csv_item.move(\"Open Data\")\n",
    "\n",
    "            if csv_lyr[\"ownerFolder\"] is None:\n",
    "                print('Moving Feature Service to Open Data Folder')\n",
    "                csv_lyr.move(\"Open Data\")\n",
    "            return csv_lyr\n",
    "        else:\n",
    "            return None\n",
    "    except:\n",
    "        print(\"Unexpected error:\", sys.exc_info()[0])\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect SDG Metadata\n",
    "For each new Item published, we can use the SDG Metadata API to return all the metadata associated with that layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getMetadata(value):\n",
    "    try:\n",
    "        url = metadata_url + \"/goals?ids=\" + value\n",
    "        req = request.Request(url)\n",
    "        response = urlopen.urlopen(req)\n",
    "        response_bytes = response.read()\n",
    "        json_data = json.loads(response_bytes.decode(\"UTF-8\"))\n",
    "        if int(value) < 10:\n",
    "            key = \"0\" + str(value)\n",
    "        else:\n",
    "            key = str(value)\n",
    "\n",
    "        if \"icon_url_sq\" not in json_data[\"data\"][0]:\n",
    "            json_data[\"data\"][0][\"icon_url_sq\"] = \"https://raw.githubusercontent.com/UNStats-SDGs/sdg-metadata-api/master/icons/SDG\" + key + \".png\"\n",
    "        return json_data[\"data\"][0]\n",
    "    except:\n",
    "        return \"https://raw.githubusercontent.com/UNStats-SDGs/sdgs-data/master/images/en/TGG_Icon_Color_\" + value + \".png\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect SDG Series Metadata\n",
    "Information such as standard Tags can also be retrieved from the SDG Metadata API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_series_tags(series_code):\n",
    "    try:\n",
    "        url = metadata_url + \"/series?code=\" + series_code\n",
    "        print(url)\n",
    "        req = request.Request(url)\n",
    "        response = urlopen.urlopen(req)\n",
    "        response_bytes = response.read()\n",
    "        json_data = json.loads(response_bytes.decode(\"UTF-8\"))\n",
    "        if \"tags\" not in json_data[\"data\"][0]:\n",
    "            return []\n",
    "        return json_data[\"data\"][0][\"tags\"]\n",
    "    except:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createGroup(group_info):\n",
    "    try:\n",
    "        # Add the Service Definition to the Enterprise site\n",
    "        item_properties = dict({\n",
    "            \"title\": group_info[\"title\"],\n",
    "            \"snippet\": group_info[\"snippet\"],\n",
    "            \"description\": group_info[\"description\"],\n",
    "            \"tags\": \", \".join([group_info[\"title\"], \"Open Data\", \"Hub\"]),\n",
    "            \"thumbnail\": group_info[\"thumbnail\"],\n",
    "            \"isOpenData\": True,\n",
    "            \"access\": \"public\",\n",
    "            \"isInvitationOnly\": True,\n",
    "            \"protected\": True\n",
    "        })\n",
    "\n",
    "        # Check if there is a group here\n",
    "        query_string = \"title:'{}' AND owner:{}\".format(group_info[\"title\"], online_username)\n",
    "        search_results = gis_online_connection.groups.search(query_string)\n",
    "        if not search_results:\n",
    "            # Update the group information\n",
    "            group = gis_online_connection.groups.create_from_dict(item_properties)\n",
    "            display(group)\n",
    "            return group\n",
    "        else:\n",
    "            for search_result in search_results:\n",
    "                if search_result[\"title\"] == group_info[\"title\"]:\n",
    "                    group_found = True\n",
    "                    search_result.update(title=group_info[\"title\"], tags=group_info[\"tags\"],\n",
    "                                         description=group_info[\"description\"],\n",
    "                                         snippet=group_info[\"snippet\"], access=\"Public\",\n",
    "                                         thumbnail=group_info[\"thumbnail\"])\n",
    "                    return search_result\n",
    "            # the group was not in the returned search results so create now\n",
    "            group = gis_online_connection.groups.create_from_dict(item_properties)\n",
    "            display(group)\n",
    "            return  group\n",
    "    except:\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addItemtoOnline(item_properties, thumbnail):\n",
    "    # Check if there is a group here\n",
    "    query_string = \"title:'{}' AND owner:{}\".format(item_properties[\"title\"], online_username)\n",
    "    search_results = gis_online_connection.content.search(query_string)\n",
    "    if not search_results:\n",
    "        return gis_online_connection.content.add(item_properties=item_properties, thumbnail=thumbnail)\n",
    "    else:\n",
    "        for search_result in search_results:\n",
    "            if search_result[\"title\"] == item_properties[\"title\"]:\n",
    "                search_result.update(item_properties=item_properties, thumbnail=thumbnail)\n",
    "                display(search_result)\n",
    "                return search_result\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Group for each SDG Goal\n",
    "You can create a Group within your ArcGIS Online Organization for each SDG. As you publish Items, you can share them to the relevant Group(s). This function will create the Group, query the SDG Metadata API to return the Title, Summary, Description, Tags, and Thumbnail for that particular SDG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  Get the JSON Values from the SDG API\n",
    "url = \"https://unstats.un.org/SDGAPI/v1/sdg/Goal/List?includechildren=true\"\n",
    "req = request.Request(url)\n",
    "response = urlopen.urlopen(req)\n",
    "response_bytes = response.read()\n",
    "json_data = json.loads(response_bytes.decode(\"UTF-8\"))\n",
    "\n",
    "for goal in json_data:\n",
    "    # Determine if we are processing this query Only process a specific series code\n",
    "    #if goal_code is not None and int(goal[\"code\"]) not in goal_code:\n",
    "    #    continue\n",
    "\n",
    "    # Get the Thumbnail from the SDG API\n",
    "    goal_metadata = getMetadata(goal[\"code\"])\n",
    "    print(goal_metadata)\n",
    "    \n",
    "    if \"icon_url_sq\" in goal_metadata:\n",
    "        thumbnail = goal_metadata[\"icon_url_sq\"]\n",
    "    else:\n",
    "        thumbnail = \"http://undesa.maps.arcgis.com/sharing/rest/content/items/aaa0678dba0a466e8efef6b9f11775fe/data\"\n",
    "\n",
    "    # Create a Group for the Goal\n",
    "    group_goal_properties = dict()\n",
    "    group_goal_properties[\"title\"] = \"SDG \" + goal[\"code\"]\n",
    "    group_goal_properties[\"snippet\"] = goal[\"title\"]\n",
    "    group_goal_properties[\"description\"] = goal[\"description\"]\n",
    "    group_goal_properties[\"tags\"] = [group_goal_properties[\"title\"]]\n",
    "\n",
    "    group_goal_properties[\"thumbnail\"] = thumbnail\n",
    "    group_id = createGroup(group_goal_properties)\n",
    "\n",
    "    for target in goal[\"targets\"]:\n",
    "        group_target_properties = dict()\n",
    "        group_target_properties[\"tags\"] = [\"Target \" + target[\"code\"]]\n",
    "        group_id.update(tags=group_id[\"tags\"] + group_target_properties[\"tags\"])\n",
    "\n",
    "        # Iterate through each of the targets\n",
    "        # Allow processing a single indicator\n",
    "        for indicator in target[\"indicators\"]:\n",
    "            #if indicator_code and not indicator[\"code\"] == indicator_code:\n",
    "            #    continue\n",
    "\n",
    "            process_indicator = dict()\n",
    "            process_indicator[\"name\"] = \"Indicator \" + indicator[\"code\"]  # eg. Indicator 1.1.1\n",
    "            process_indicator[\"tags\"] = [process_indicator[\"name\"]]\n",
    "            # Append the keyword tags from the metadata as well\n",
    "            group_id.update(tags=group_id[\"tags\"] + process_indicator[\"tags\"])\n",
    "\n",
    "            process_indicator[\"snippet\"] = indicator[\"code\"] + \": \" + indicator[\"description\"]\n",
    "            process_indicator[\"description\"] = \"<p><b>Indicator \" + indicator[\"code\"] + \": </b>\" + indicator[\"description\"] + \"</p>\" + \\\n",
    "                                               \"</p><p><b>Target \" + target[\"code\"] + \": </b>\" + target[\"description\"] + \"</p>\" + \\\n",
    "                                               \"<p>\" + goal[\"description\"] + \"</p>\"\n",
    "\n",
    "            process_indicator[\"credits\"] = \"UNSD\"\n",
    "            process_indicator[\"thumbnail\"] = thumbnail\n",
    "\n",
    "            for series in indicator[\"series\"]:\n",
    "                # Determine if we are processing this query Only process a specific series code\n",
    "                #if indicator_code and not (series[\"code\"] == series_code or series_code is None):\n",
    "                #    continue\n",
    "\n",
    "                # indicator_code = None\n",
    "                item_properties = dict()\n",
    "                item_properties[\"title\"] = process_indicator[\"name\"] + \" (\" + series[\"code\"] + \"): \" + series[\"description\"]\n",
    "                if not series[\"description\"]:\n",
    "                    series[\"description\"] = series[\"code\"]\n",
    "                snippet = series[\"code\"] + \": \" + series[\"description\"]\n",
    "                item_properties[\"snippet\"] = (snippet[:250] + \"..\") if len(snippet) > 250 else snippet\n",
    "                item_properties[\"description\"] = \"<p><b>Series \" + series[\"code\"] + \": </b>\" + \\\n",
    "                                                 series[\"description\"] + \"</p>\" + \\\n",
    "                                                 process_indicator[\"description\"]\n",
    "                final_tags = group_goal_properties[\"tags\"] + \\\n",
    "                                group_target_properties[\"tags\"] + \\\n",
    "                                process_indicator[\"tags\"]\n",
    "                final_tags.extend(get_series_tags(series[\"code\"]))\n",
    "                #final_tags = set(final_tags)\n",
    "                #final_tags = list(final_tags)\n",
    "                item_properties[\"tags\"] = final_tags\n",
    "\n",
    "                # Add this item to ArcGIS Online\n",
    "                print(\"Processing series code:\", indicator[\"code\"], series[\"code\"])\n",
    "                try:\n",
    "                    online_item = publish_csv(series[\"code\"], item_properties=item_properties,\n",
    "                                              thumbnail=thumbnail)\n",
    "                    display(online_item)\n",
    "                    \n",
    "                    if online_item is not None:\n",
    "                        # Share this content with the goals group\n",
    "                        online_item.share(everyone=True, org=True, groups=group_id[\"id\"],\n",
    "                                          allow_members_to_edit=False)\n",
    "                        # Update the Group Information with Data from the Indicator and targets\n",
    "                        group_id.update(tags=group_id[\"tags\"] + [series[\"code\"]])\n",
    "                except:\n",
    "                    traceback.print_exc()\n",
    "                    print(\"Failed to process series code:\", indicator[\"code\"], series[\"code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
